
@article{kiefe_identifying_1998,
	title = {Identifying achievable benchmarks of care: concepts and methodology},
	volume = {10},
	copyright = {Oxford University Press},
	issn = {1353-4505, 1464-3677},
	shorttitle = {Methodology matters-{XII}. {Identifying} achievable benchmarks of care},
	url = {http://intqhc.oxfordjournals.org/content/10/5/443},
	doi = {10.1093/intqhc/10.5.443},
	abstract = {Webster's Dictionary defines a benchmark as 'something that serves as a standard by which others can be measured'. Benchmarking pervades the health care quality improvement literature, and benchmarks are usually based on subjective assessment rather than on measurements derived from data. As such, benchmarks may fail to yield an achievable level of excellence that can be replicated under specific conditions. In this paper, we provide an overview of benchmarking in health care. We then describe the evolution of our data-driven method for identifying an Achievable Benchmark of Care (ABCTM) on the basis of process-of-care indicators. Here, our experience leads us to postulate the following premises for sound benchmarks: (i) benchmarks should represent a level of excellence; (ii) benchmarks should be demonstrably attainable; (iii) providers with high performance should be selected from among all providers in a predefined way using reliable data; (iv) all providers with high performance levels should contribute to the benchmark level; and (v) providers with high performance levels but small numbers of cases should not unduly influence the level of the benchmark.An example of an ABCTM applied to the cooperative cardiovascular project leads the reader through the computation of an ABCTM. Finally, we consider several refinements of the original ABCTM concept that are in progress, e.g. how to approach the special problems posed by very small denominators.The ABCTM methodology has been well accepted in multiple quality improvement projects. This approach lends objectivity and reliability to benchmarks that have been a widely used, but until now, arbitrarily defined tool.Keywords:benchmarks, continuous quality improvement, feedback, outcomes, quality improvement},
	language = {en},
	number = {5},
	urldate = {2016-10-23},
	journal = {International Journal for Quality in Health Care},
	author = {Kiefe, C. I. and Weissman, N. W. and Allison, J. J. and Farmer, R. and Weaver, M. and Williams, O. D.},
	month = oct,
	year = {1998},
	pmid = {9828034},
	pages = {443--447},
	file = {Full Text PDF:C\:\\Users\\Rollie\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\szvc8raq.default\\zotero\\storage\\P8FDNDSC\\Kiefe et al. - 1998 - Methodology matters-XII. Identifying achievable be.pdf:application/pdf;Snapshot:C\:\\Users\\Rollie\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\szvc8raq.default\\zotero\\storage\\TAAWV2ID\\443.html:text/html}
}

@article{parikh_establishing_2014,
	title = {Establishing {Benchmarks} for the {Hospitalized} {Care} of {Children} {With} {Asthma}, {Bronchiolitis}, and {Pneumonia}},
	copyright = {Copyright © 2014 by the American Academy of Pediatrics},
	issn = {0031-4005, 1098-4275},
	url = {http://pediatrics.aappublications.org/content/early/2014/08/12/peds.2014-1052},
	doi = {10.1542/peds.2014-1052},
	abstract = {BACKGROUND AND OBJECTIVES: Asthma, pneumonia, and bronchiolitis are the leading causes of admission for pediatric patients; however, the lack of accepted benchmarks is a barrier to quality improvement efforts. Using data from children hospitalized with asthma, bronchiolitis, or pneumonia, the goals of this study were to: (1) measure the 2012 performance of freestanding children’s hospitals using clinical quality indicators; and (2) construct achievable benchmarks of care (ABCs) for the clinical quality indicators.
METHODS: This study was a cross-sectional trial using the Pediatric Health Information System database. Patient inclusions varied according to diagnosis: asthma (International Classification of Diseases, Ninth Revision, Clinical Modification [ICD-9-CM] codes 493.0–493.92) from 2 to 18 years of age; bronchiolitis (ICD-9-CM codes 466.11 and 466.19) from 2 months to 2 years of age; and pneumonia (ICD-9-CM codes 480–486, 487.0) from 2 months to 18 years of age. ABC methods use the best-performing hospitals that comprise at least 10\% of the total population to compute the benchmark.
RESULTS: Encounters from 42 hospitals included: asthma, 22 186; bronchiolitis, 14 882; and pneumonia, 12 983. Asthma ABCs include: chest radiograph utilization, 24.5\%; antibiotic administration, 6.6\%; and ipratropium bromide use {\textgreater}2 days, 0\%. Bronchiolitis ABCs include: chest radiograph utilization, 32.4\%; viral testing, 0.6\%; antibiotic administration, 18.5\%; bronchodilator use {\textgreater}2 days, 11.4\%; and steroid use, 6.4\%. Pneumonia ABCs include: complete blood cell count utilization, 28.8\%; viral testing, 1.5\%; initial narrow-spectrum antibiotic use, 60.7\%; erythrocyte sedimentation rate, 3.5\%; and C-reactive protein, 0.1\%.
CONCLUSIONS: We report achievable benchmarks for inpatient care for asthma, bronchiolitis, and pneumonia. The establishment of national benchmarks will drive improvement at individual hospitals.},
	language = {en},
	urldate = {2016-10-23},
	journal = {Pediatrics},
	author = {Parikh, Kavita and Hall, Matt and Mittal, Vineeta and Montalbano, Amanda and Mussman, Grant M. and Morse, Rustin B. and Hain, Paul and Wilson, Karen M. and Shah, Samir S.},
	month = aug,
	year = {2014},
	pmid = {25136044},
	keywords = {asthma, benchmarks, bronchiolitis, quality improvement},
	pages = {peds.2014--1052},
	file = {Full Text PDF:C\:\\Users\\Rollie\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\szvc8raq.default\\zotero\\storage\\UZC7HWRZ\\Parikh et al. - 2014 - Establishing Benchmarks for the Hospitalized Care .pdf:application/pdf;Snapshot:C\:\\Users\\Rollie\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\szvc8raq.default\\zotero\\storage\\8E42UJCN\\peds.html:text/html}
}

@article{hatfield_surgeon-specific_2016,
	title = {Surgeon-{Specific} {Reports} in {General} {Surgery}: {Establishing} {Benchmarks} for {Peer} {Comparison} {Within} a {Single} {Hospital}},
	volume = {222},
	issn = {1072-7515, 1879-1190},
	shorttitle = {Surgeon-{Specific} {Reports} in {General} {Surgery}},
	url = {http://www.journalacs.org/article/S1072-7515(15)01714-7/abstract},
	doi = {10.1016/j.jamcollsurg.2015.10.017},
	abstract = {Background
Methods to assess a surgeon's individual performance based on clinically meaningful outcomes have not been fully developed, due to small numbers of adverse outcomes and wide variation in case volumes. The Achievable Benchmark of Care (ABC) method addresses these issues by identifying benchmark-setting surgeons with high levels of performance and greater case volumes. This method was used to help surgeons compare their surgical practice to that of their peers by using merged National Surgical Quality Improvement Program (NSQIP) and Metabolic and Bariatric Surgery Accreditation and Quality Improvement Program (MBSAQIP) data to generate surgeon-specific reports.
Study design
A retrospective cohort study at a single institution's department of surgery was conducted involving 107 surgeons (8,660 cases) over 5.5 years. Stratification of more than 32,000 CPT codes into 16 CPT clusters served as the risk adjustment. Thirty-day outcomes of interest included surgical site infection (SSI), acute kidney injury (AKI), and mortality. Performance characteristics of the ABC method were explored by examining how many surgeons were identified as benchmark-setters in view of volume and outcome rates within CPT clusters.
Results
For the data captured, most surgeons performed cases spanning a median of 5 CPT clusters (range 1 to 15 clusters), with a median of 26 cases (range 1 to 776 cases) and a median of 2.8 years (range 0 to 5.5 years). The highest volume surgeon for that CPT cluster set the benchmark for 6 of 16 CPT clusters for SSIs, 8 of 16 CPT clusters for AKIs, and 9 of 16 CPT clusters for mortality.
Conclusions
The ABC method appears to be a sound and useful approach to identifying benchmark-setting surgeons within a single institution. Such surgeons may be able to help their peers improve their performance.},
	language = {English},
	number = {2},
	urldate = {2016-10-23},
	journal = {Journal of the American College of Surgeons},
	author = {Hatfield, Mark D. and Ashton, Carol M. and Bass, Barbara L. and Shirkey, Beverly A.},
	month = feb,
	year = {2016},
	pmid = {26725243},
	keywords = {ABC, Achievable Benchmark of Care, acute kidney injury, adjusted performance fraction, AKI, APF, MBSAQIP, Metabolic and Bariatric Surgery Accreditation and Quality Improvement Program, SSI, surgical site infection},
	pages = {113--121},
	file = {Snapshot:C\:\\Users\\Rollie\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\szvc8raq.default\\zotero\\storage\\JDS89JEQ\\abstract.html:text/html}
}

@article{gardner_reported_2014,
	title = {Reported findings on endoscopic ultrasound examinations for chronic pancreatitis: toward establishing an endoscopic ultrasound quality benchmark},
	volume = {43},
	issn = {1536-4828},
	shorttitle = {Reported findings on endoscopic ultrasound examinations for chronic pancreatitis},
	doi = {10.1097/MPA.0b013e3182a85e1e},
	abstract = {OBJECTIVES: Endoscopic ultrasound (EUS) quality benchmarks for pancreatic disease previously focused on maintaining thresholds of diagnostic accuracy for fine-needle aspiration and measuring complications. We aimed to evaluate quality indicators when performing EUS specifically for the diagnosis of chronic pancreatitis (CP).
METHODS: Using a single-center EUS database, we identified patients who underwent an EUS since 2001 specifically for the indication of (1) suspected CP, (2) exclusion of CP, or (3) established CP. Each EUS report was evaluated for the number of parenchymal and ductal criteria as per minimal standards terminology criteria.
RESULTS: Two hundred eighty-six EUS examinations performed by 4 endosonographers were included. The mean number of reported evaluated parenchymal criteria was 2.44 (median, 2), and that of ductal criteria was 2.41 (median, 2). There was a difference among endosonographers in terms of mean number of total criteria reported evaluated (P {\textless} 0.001): endosonographer 1 = 3.9 (n = 174 examinations), endosonographer 2 = 6.8 (n = 86 examinations), endosonographer 3 = 6.2 (n = 13 examinations), and endosonographer 4 = 2.5 (n = 11 examinations). However, there was no difference between endosonographers in the number of total (parenchymal and ductal) criteria found.
CONCLUSIONS: There was a discrepancy among endosonographers when reporting which EUS findings were evaluated in patients undergoing EUS specifically to diagnose CP.},
	language = {ENG},
	number = {1},
	journal = {Pancreas},
	author = {Gardner, Timothy B. and Taylor, Dean J. and Gordon, Stuart R.},
	month = jan,
	year = {2014},
	pmid = {24177140},
	pmcid = {PMC3864114},
	keywords = {Databases, Factual, Endosonography, Female, Humans, Male, Middle Aged, Pancreatitis, Chronic, Reproducibility of Results, Sensitivity and Specificity},
	pages = {37--40}
}